{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45cc08b1",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "\n",
    "This is the file that contains the working code for the MNIST model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c49786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 0. Imports\n",
    "# ===========================\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ===========================\n",
    "# 1. Data (MNIST)\n",
    "# ===========================\n",
    "image_size = 28\n",
    "batch_size = 128\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),                  # [0,1]\n",
    "    transforms.Normalize(0.5, 0.5),         # [-1,1]\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# ===========================\n",
    "# 2. Time Embeddings\n",
    "# ===========================\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard sinusoidal positional embedding for scalar timestep t.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, t):\n",
    "        \"\"\"\n",
    "        t: (B,) int or float timesteps\n",
    "        returns: (B, dim)\n",
    "        \"\"\"\n",
    "        device = t.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb_factor = math.log(10000) / (half_dim - 1)\n",
    "        # exponents: [0, 1, 2, ..., half_dim-1]\n",
    "        exponents = torch.exp(torch.arange(half_dim, device=device) * -emb_factor)\n",
    "        # t: (B,1), exponents: (half_dim,) -> (B, half_dim)\n",
    "        t = t.float().unsqueeze(1)\n",
    "        angles = t * exponents[None, :]\n",
    "        emb = torch.cat([torch.sin(angles), torch.cos(angles)], dim=-1)\n",
    "        if self.dim % 2 == 1:\n",
    "            # pad if odd\n",
    "            emb = F.pad(emb, (0, 1))\n",
    "        return emb\n",
    "\n",
    "# ===========================\n",
    "# 3. UNet building blocks\n",
    "# ===========================\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, time_dim):\n",
    "        super().__init__()\n",
    "        self.time_dim = time_dim\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "\n",
    "        self.time_mlp = nn.Linear(time_dim, out_channels)\n",
    "\n",
    "        self.norm1 = nn.GroupNorm(8, out_channels)\n",
    "        self.norm2 = nn.GroupNorm(8, out_channels)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "        if in_channels != out_channels:\n",
    "            self.res_conv = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        else:\n",
    "            self.res_conv = nn.Identity()\n",
    "\n",
    "    def forward(self, x, t_emb):\n",
    "        \"\"\"\n",
    "        x: (B, C, H, W)\n",
    "        t_emb: (B, time_dim)\n",
    "        \"\"\"\n",
    "        h = self.conv1(x)\n",
    "        # inject time\n",
    "        t_added = self.time_mlp(t_emb)[:, :, None, None]\n",
    "        h = h + t_added\n",
    "        h = self.act(self.norm1(h))\n",
    "\n",
    "        h = self.conv2(h)\n",
    "        h = self.act(self.norm2(h))\n",
    "\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, time_dim):\n",
    "        super().__init__()\n",
    "        self.resblock = ResidualBlock(in_channels, out_channels, time_dim)\n",
    "        self.down = nn.Conv2d(out_channels, out_channels, 4, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x, t_emb):\n",
    "        x = self.resblock(x, t_emb)\n",
    "        skip = x\n",
    "        x = self.down(x)\n",
    "        return x, skip\n",
    "\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, skip_channels, time_dim):\n",
    "        \"\"\"\n",
    "        in_channels: channels coming from below\n",
    "        out_channels: channels after upsample\n",
    "        skip_channels: channels from the skip connection\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, out_channels, 4, stride=2, padding=1)\n",
    "        self.resblock = ResidualBlock(out_channels + skip_channels, out_channels, time_dim)\n",
    "\n",
    "    def forward(self, x, skip, t_emb):\n",
    "        x = self.up(x)\n",
    "        # concatenate along channel dimension\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.resblock(x, t_emb)\n",
    "        return x\n",
    "\n",
    "# ===========================\n",
    "# 4. UNet model\n",
    "# ===========================\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, base_channels=64, time_dim=128, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.base_channels = base_channels\n",
    "        self.time_dim = time_dim\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Time embedding: sinusoidal + MLP\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPosEmb(time_dim),\n",
    "            nn.Linear(time_dim, time_dim * 4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_dim * 4, time_dim),\n",
    "        )\n",
    "\n",
    "        # Class embedding (for conditional generation)\n",
    "        self.label_emb = nn.Embedding(num_classes, time_dim)\n",
    "\n",
    "        # Initial conv\n",
    "        self.init_conv = nn.Conv2d(in_channels, base_channels, 3, padding=1)\n",
    "\n",
    "        # Encoder\n",
    "        chs = [base_channels, base_channels * 2, base_channels * 4]  # [64,128,256]\n",
    "        self.down1 = DownBlock(chs[0], chs[1], time_dim)\n",
    "        self.down2 = DownBlock(chs[1], chs[2], time_dim)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = ResidualBlock(chs[2], chs[2], time_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.up2 = UpBlock(chs[2], chs[1], skip_channels=chs[2], time_dim=time_dim)\n",
    "        self.up1 = UpBlock(chs[1], chs[0], skip_channels=chs[1], time_dim=time_dim)\n",
    "\n",
    "        # Final conv to go back to 1 channel (noise prediction)\n",
    "        self.out_conv = nn.Conv2d(base_channels, in_channels, 1)\n",
    "\n",
    "    def forward(self, x, t, y=None):\n",
    "        \"\"\"\n",
    "        x: (B, 1, 28, 28) noisy image\n",
    "        t: (B,) integer timesteps\n",
    "        y: (B,) labels 0..9 (optional)\n",
    "        \"\"\"\n",
    "        # time embedding\n",
    "        t_emb = self.time_mlp(t)  # (B, time_dim)\n",
    "\n",
    "        # class conditioning\n",
    "        if y is not None:\n",
    "            y_emb = self.label_emb(y)  # (B, time_dim)\n",
    "            t_emb = t_emb + y_emb\n",
    "\n",
    "        # UNet\n",
    "        x = self.init_conv(x)  # -> (B, 64, 28, 28)\n",
    "\n",
    "        x, skip1 = self.down1(x, t_emb)  # x: (B, 128, 14, 14), skip1: (B, 128, 28, 28)\n",
    "        x, skip2 = self.down2(x, t_emb)  # x: (B, 256, 7, 7),  skip2: (B, 256, 14, 14)\n",
    "\n",
    "        x = self.bottleneck(x, t_emb)   # (B, 256, 7, 7)\n",
    "\n",
    "        x = self.up2(x, skip2, t_emb)   # (B, 128, 14, 14)\n",
    "        x = self.up1(x, skip1, t_emb)   # (B, 64, 28, 28)\n",
    "\n",
    "        x = self.out_conv(x)            # (B, 1, 28, 28)\n",
    "        return x  # predicted noise ε̂\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# 5. Diffusion utilities (DDPM-style)\n",
    "# ===========================\n",
    "class Diffusion:\n",
    "    def __init__(self, num_steps=1000, beta_start=1e-4, beta_end=0.02, device=\"cpu\"):\n",
    "        self.device = device\n",
    "        self.num_steps = num_steps\n",
    "\n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_steps, device=device)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alpha_cumprod = torch.cumprod(self.alphas, dim=0)\n",
    "        self.alpha_cumprod_prev = torch.cat(\n",
    "            [torch.tensor([1.0], device=device), self.alpha_cumprod[:-1]], dim=0\n",
    "        )\n",
    "\n",
    "        # For sampling\n",
    "        self.sqrt_alphas = torch.sqrt(self.alphas)\n",
    "        self.sqrt_one_minus_alpha_cumprod = torch.sqrt(1.0 - self.alpha_cumprod)\n",
    "        self.sqrt_alpha_cumprod = torch.sqrt(self.alpha_cumprod)\n",
    "\n",
    "        # Posterior variance for q(x_{t-1} | x_t, x_0)\n",
    "        self.posterior_variance = (\n",
    "            self.betas\n",
    "            * (1.0 - self.alpha_cumprod_prev)\n",
    "            / (1.0 - self.alpha_cumprod)\n",
    "        )\n",
    "        self.posterior_log_variance_clipped = torch.log(\n",
    "            torch.clamp(self.posterior_variance, min=1e-20)\n",
    "        )\n",
    "\n",
    "    def sample_timesteps(self, batch_size):\n",
    "        \"\"\"\n",
    "        Uniformly sample timesteps t in [0, num_steps-1]\n",
    "        \"\"\"\n",
    "        return torch.randint(0, self.num_steps, (batch_size,), device=self.device).long()\n",
    "\n",
    "    def q_sample(self, x0, t, noise=None):\n",
    "        \"\"\"\n",
    "        Diffuse the data (forward process): q(x_t | x_0)\n",
    "        x0: (B, C, H, W)\n",
    "        t:  (B,) timesteps\n",
    "        \"\"\"\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x0)\n",
    "        # gather alpha_cumprod for each t\n",
    "        sqrt_alpha_cumprod_t = self.sqrt_alpha_cumprod[t].view(-1, 1, 1, 1)\n",
    "        sqrt_one_minus_alpha_cumprod_t = self.sqrt_one_minus_alpha_cumprod[t].view(-1, 1, 1, 1)\n",
    "        return sqrt_alpha_cumprod_t * x0 + sqrt_one_minus_alpha_cumprod_t * noise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, model, x_t, t, y=None):\n",
    "        \"\"\"\n",
    "        One reverse step: p(x_{t-1} | x_t)\n",
    "        x_t: (B, 1, 28, 28)\n",
    "        t: scalar int timestep (not batch)\n",
    "        \"\"\"\n",
    "        B = x_t.size(0)\n",
    "        t_batch = torch.full((B,), t, device=self.device, dtype=torch.long)\n",
    "\n",
    "        # predict noise at this timestep\n",
    "        eps_theta = model(x_t, t_batch, y)\n",
    "\n",
    "        beta_t = self.betas[t]\n",
    "        alpha_t = self.alphas[t]\n",
    "        alpha_cumprod_t = self.alpha_cumprod[t]\n",
    "        sqrt_one_minus_alpha_cumprod_t = self.sqrt_one_minus_alpha_cumprod[t]\n",
    "        sqrt_recip_alpha_t = (1.0 / torch.sqrt(alpha_t))\n",
    "\n",
    "        # Estimate x_0 from x_t and ε̂\n",
    "        # x_0 ≈ (x_t - sqrt(1 - ᾱ_t) * εθ) / sqrt(ᾱ_t)\n",
    "        # (not strictly needed here but good to keep in mind)\n",
    "        # Use the DDPM formula for the mean:\n",
    "        # μθ(x_t, t) = 1/sqrt(α_t) * (x_t - β_t / sqrt(1 - ᾱ_t) * εθ)\n",
    "        model_mean = sqrt_recip_alpha_t * (\n",
    "            x_t - (beta_t / sqrt_one_minus_alpha_cumprod_t) * eps_theta\n",
    "        )\n",
    "\n",
    "        if t == 0:\n",
    "            return model_mean\n",
    "        else:\n",
    "            posterior_var_t = self.posterior_variance[t]\n",
    "            noise = torch.randn_like(x_t)\n",
    "            return model_mean + torch.sqrt(posterior_var_t) * noise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, model, image_size, batch_size=16, y=None):\n",
    "        \"\"\"\n",
    "        Generate samples from pure noise.\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        x = torch.randn(batch_size, 1, image_size, image_size, device=self.device)\n",
    "\n",
    "        # If conditional and y is None, randomly choose labels\n",
    "        if y is None:\n",
    "            y = torch.randint(0, 10, (batch_size,), device=self.device)\n",
    "\n",
    "        for t in reversed(range(self.num_steps)):\n",
    "            x = self.p_sample(model, x, t, y=y)\n",
    "\n",
    "        return x   # in [-1,1] (approximately)\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# 6. Model + Diffusion setup\n",
    "# ===========================\n",
    "time_dim = 128\n",
    "model = UNet(\n",
    "    in_channels=1,\n",
    "    base_channels=64,\n",
    "    time_dim=time_dim,\n",
    "    num_classes=10\n",
    ").to(device)\n",
    "\n",
    "num_steps = 1000\n",
    "diffusion = Diffusion(\n",
    "    num_steps=num_steps,\n",
    "    beta_start=1e-4,\n",
    "    beta_end=0.02,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "\n",
    "# ===========================\n",
    "# 7. Training Loop\n",
    "# ===========================\n",
    "num_epochs = 10  # bump this up (e.g. 50+) for better samples\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for x, labels in train_loader:\n",
    "        x = x.to(device)           # already normalized to [-1,1]\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        b = x.size(0)\n",
    "        t = diffusion.sample_timesteps(b)  # (B,)\n",
    "\n",
    "        noise = torch.randn_like(x)\n",
    "        x_t = diffusion.q_sample(x, t, noise=noise)\n",
    "\n",
    "        # predict the noise\n",
    "        pred_noise = model(x_t, t, y=labels)\n",
    "\n",
    "        loss = F.mse_loss(pred_noise, noise)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * b\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {epoch_loss:.6f}\")\n",
    "\n",
    "print(\"Training done.\")\n",
    "\n",
    "# ===========================\n",
    "# 8. Sampling & Visualization\n",
    "# ===========================\n",
    "@torch.no_grad()\n",
    "def show_samples(model, diffusion, n=16, class_label=None):\n",
    "    model.eval()\n",
    "    if class_label is None:\n",
    "        # random labels\n",
    "        y = torch.randint(0, 10, (n,), device=device)\n",
    "    else:\n",
    "        y = torch.full((n,), class_label, device=device, dtype=torch.long)\n",
    "\n",
    "    samples = diffusion.sample(model, image_size=image_size, batch_size=n, y=y)\n",
    "    # de-normalize from [-1,1] back to [0,1]\n",
    "    samples = (samples.clamp(-1, 1) + 1) / 2.0\n",
    "\n",
    "    grid = utils.make_grid(samples, nrow=int(math.sqrt(n)))\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
    "    plt.show()\n",
    "\n",
    "# Example: generate random digits\n",
    "show_samples(model, diffusion, n=16, class_label=None)\n",
    "\n",
    "# Example: generate only \"3\"s\n",
    "# show_samples(model, diffusion, n=16, class_label=3)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
